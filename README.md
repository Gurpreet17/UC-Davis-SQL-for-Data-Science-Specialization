# Distributed-Computing-with-Spark-SQL
My GitHub repository is a comprehensive collection of materials from the course I completed on Coursera. The course primarily focuses on big data and aims to guide students with prior SQL experience towards mastering distributed computing using Apache Spark. Throughout the course, I gained a deep understanding of Spark, which is an open-source standard for handling large datasets efficiently. By leveraging Spark SQL, I learned how to perform data analysis and combine it with advanced analytics on a scalable level, especially in real-world production environments.

The repository is organized into four modules, each building upon the previous one to provide a cohesive learning experience. In the first module, I was introduced to Spark and the Databricks environment. I learned about the Spark architecture, how it distributes computations, and its integration with Spark SQL. Module 2 delved into the core concepts of Spark, covering essential topics like storage vs. compute, caching, partitioning, and troubleshooting performance issues using the Spark UI. Additionally, this module explored new features introduced in Apache Spark 3.x, such as Adaptive Query Execution.

Moving on to module 3, the focus shifted towards engineering data pipelines. This module covered important aspects like connecting to databases, understanding schemas and data types, working with various file formats, and developing reliable data pipelines. Finally, the fourth module explored the realm of data lakes, data warehouses, and lakehouses. Here, I had the opportunity to build production-grade data pipelines by integrating Spark with the open-source Delta Lake project. By combining these technologies, I gained hands-on experience in creating a medallion architecture (bronze, silver, gold) to ensure the reliability, scalability, and performance of data.

Throughout the course, I honed my skills in writing scalable Spark SQL code within the collaborative Databricks workspace. I also became proficient in utilizing the Spark UI to analyze query performance, identify bottlenecks, and optimize Spark SQL queries. Furthermore, I learned how to construct end-to-end pipelines that encompass data ingestion, transformation, and storage. The culmination of the course allowed me to proficiently build medallion lakehouse architectures using Delta Lake, empowering me with the ability to work with data reliably and efficiently.

In conclusion, this repository showcases the materials and resources I acquired during my completion of the course. By exploring its contents, one can gain insights into the fundamentals of Spark, advanced Spark SQL techniques, data pipeline engineering, and the integration of Spark with Delta Lake. These learnings have elevated my SQL and distributed computing skills, enabling me to excel in advanced analysis tasks and paving the way for a smooth transition into more advanced analytics as a Data Scientist.

![image](https://github.com/Gurpreet17/Distributed-Computing-with-Spark-SQL/assets/74424705/df056123-a931-4c57-8b27-2b826ab2a0db)
